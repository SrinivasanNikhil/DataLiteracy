{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python Pandas - Text.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN18oboT+yTnCWMZv/j7GuG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SrinivasanNikhil/DataLiteracy/blob/master/Python_Pandas_Text_DateTime.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zONdsU7M-obR"
      },
      "source": [
        "# Python Pandas\n",
        "\n",
        "## Working with text data\n",
        "\n",
        "The pandas pakage allows us to work with text data and perform a vareity of [operations](https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html#working-with-text-data) on them. \n",
        "\n",
        "Below you will find some examples of operations to perform on text data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CjIsgvS-now"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "pd.set_option(\"display.max_rows\", 100, \"display.max_columns\", 100)\n",
        "\n",
        "data = pd.read_excel(\"https://elasticbeanstalk-us-east-1-712866102994.s3.amazonaws.com/data/TwitterSearch.xlsx\")\n",
        "\n",
        "print(data.head())\n",
        "\n",
        "print(data.columns)\n",
        "\n",
        "#Length of each tweet\n",
        "print(data[\"text\"].str.len())\n",
        "\n",
        "#Average length of a tweet\n",
        "print(data[\"text\"].str.len().mean())\n",
        "\n",
        "#Number of tweets\n",
        "print(data[\"text\"].count())\n",
        "\n",
        "#Number of words in the tweet\n",
        "data[\"wordcount\"] = data[\"text\"].str.split(\" \").str.len()\n",
        "print(data[[\"text\",\"wordcount\"]])\n",
        "\n",
        "#Frequency of words used in a tweet\n",
        "print(data[\"wordcount\"].value_counts())\n",
        "\n",
        "#Find tweets with purple\n",
        "\n",
        "data[\"contains\"] = data[\"text\"].str.contains(\"purple\")\n",
        "print(data[\"contains\"].value_counts())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeBVq804G9zF"
      },
      "source": [
        "#Find tweets that contain both purple and iphone\n",
        "\n",
        "#Find the number of tweets by individual accounts in the data set\n",
        "\n",
        "#How many tweets were sent from Iphones\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTFj0XC7B1oX"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "pd.set_option(\"display.max_rows\", 100, \"display.max_columns\", 100)\n",
        "\n",
        "data = pd.read_excel(\"https://elasticbeanstalk-us-east-1-712866102994.s3.amazonaws.com/data/TwitterSearch.xlsx\")\n",
        "\n",
        "#Find tweets that have a URL in them\n",
        "#Approach 1\n",
        "\n",
        "for ele in data[\"text\"]:\n",
        "  print(ele)\n",
        "  startpos = ele.find(\"https://\",0,len(ele))\n",
        "  endpos = ele.find(\" \",startpos,len(ele))\n",
        "  print(ele[startpos:endpos])\n",
        "\n",
        "\n",
        "#Approach 2\n",
        "\n",
        "def urlext(string):\n",
        "  startpos = string.find(\"https://\",0,len(string))\n",
        "  endpos = string.find(\" \",startpos,len(string))\n",
        "  return string[startpos:endpos]\n",
        "\n",
        "res = data[\"text\"].apply(urlext)\n",
        "res.head()\n",
        "res.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0h3ndt2Htcb"
      },
      "source": [
        "# Pandas Datetime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGPgUa4gHt5G",
        "outputId": "f71f771d-7278-4eb6-cfc5-51b690ab273f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "pd.set_option(\"display.max_rows\", 100, \"display.max_columns\", 100)\n",
        "\n",
        "data = pd.read_excel(\"https://elasticbeanstalk-us-east-1-712866102994.s3.amazonaws.com/data/TwitterSearch.xlsx\")\n",
        "\n",
        "#Date time work https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.html#pandas-datetimeindex\n",
        "print(type(data[\"created_at\"][0]))\n",
        "\n",
        "#Convert str to date time\n",
        "data[\"created_at\"] = pd.to_datetime(data[\"created_at\"])\n",
        "\n",
        "#extract the day of the week and store it in another column\n",
        "data[\"day\"] = data[\"created_at\"].dt.dayofweek\n",
        "#extract the hour of the tweet and store it in another column\n",
        "data[\"hour\"] = data[\"created_at\"].dt.hour\n",
        "\n",
        "print(data[[\"day\",\"text\"]].groupby(\"day\").count())\n",
        "print(data[[\"hour\",\"text\"]].groupby(\"hour\").count())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n",
            "      text\n",
            "day       \n",
            "3    12077\n",
            "4     3023\n",
            "      text\n",
            "hour      \n",
            "0     1210\n",
            "1     1155\n",
            "2      658\n",
            "15     837\n",
            "16    1760\n",
            "17    1513\n",
            "18    1385\n",
            "19    1538\n",
            "20    1334\n",
            "21    1342\n",
            "22    1249\n",
            "23    1119\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}